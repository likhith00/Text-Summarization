{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":971957,"sourceType":"datasetVersion","datasetId":366712}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers datasets evaluate rouge_score py7zr","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Login to HuggingFace","metadata":{}},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-02-18T16:20:38.564913Z","iopub.execute_input":"2024-02-18T16:20:38.565245Z","iopub.status.idle":"2024-02-18T16:20:38.785692Z","shell.execute_reply.started":"2024-02-18T16:20:38.565219Z","shell.execute_reply":"2024-02-18T16:20:38.784781Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58ed9616e95146229dc42d4ed9641666"}},"metadata":{}}]},{"cell_type":"markdown","source":"### Load Dataset","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset, DatasetDict, Dataset\n\n# Load dataset from the hub\ndataset = load_dataset(\"samsum\")\n\nmodified_data = DatasetDict({\n      \"train\":Dataset.from_dict(dataset[\"train\"][:2000]),\n      \"test\":Dataset.from_dict(dataset[\"test\"][:])\n                 })\n\nprint(f\"Train dataset size: {len(modified_data['train'])}\")\nprint(f\"Test dataset size: {len(modified_data['test'])}\")","metadata":{"execution":{"iopub.status.busy":"2024-02-18T16:21:00.451292Z","iopub.execute_input":"2024-02-18T16:21:00.451743Z","iopub.status.idle":"2024-02-18T16:21:03.625695Z","shell.execute_reply.started":"2024-02-18T16:21:00.451715Z","shell.execute_reply":"2024-02-18T16:21:03.624831Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Downloading and preparing dataset samsum/samsum (download: 2.81 MiB, generated: 10.04 MiB, post-processed: Unknown size, total: 12.85 MiB) to /root/.cache/huggingface/datasets/samsum/samsum/0.0.0/3f7dba43be72ab10ca66a2e0f8547b3590e96c2bd9f2cbb1f6bb1ec1f1488ba6...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/2.94M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5c4d9b4bfe540f7a51c66758b74ac5e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/14732 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/819 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/818 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset samsum downloaded and prepared to /root/.cache/huggingface/datasets/samsum/samsum/0.0.0/3f7dba43be72ab10ca66a2e0f8547b3590e96c2bd9f2cbb1f6bb1ec1f1488ba6. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"170a91ec4f064b3f85fc4bf1c0ecda8d"}},"metadata":{}},{"name":"stdout","text":"Train dataset size: 2000\nTest dataset size: 819\n","output_type":"stream"}]},{"cell_type":"code","source":"modified_data[\"train\"][0]","metadata":{"execution":{"iopub.status.busy":"2024-02-18T16:21:03.627584Z","iopub.execute_input":"2024-02-18T16:21:03.628526Z","iopub.status.idle":"2024-02-18T16:21:03.635297Z","shell.execute_reply.started":"2024-02-18T16:21:03.628470Z","shell.execute_reply":"2024-02-18T16:21:03.634207Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"{'id': '13818513',\n 'dialogue': \"Amanda: I baked  cookies. Do you want some?\\r\\nJerry: Sure!\\r\\nAmanda: I'll bring you tomorrow :-)\",\n 'summary': 'Amanda baked cookies and will bring Jerry some tomorrow.'}"},"metadata":{}}]},{"cell_type":"markdown","source":"### Load Tokenizer","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ncheckpoint = \"t5-small\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T16:21:08.793562Z","iopub.execute_input":"2024-02-18T16:21:08.793994Z","iopub.status.idle":"2024-02-18T16:21:14.590509Z","shell.execute_reply.started":"2024-02-18T16:21:08.793964Z","shell.execute_reply":"2024-02-18T16:21:14.589655Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a423ce1f01a47f7add240e8be1a13d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba02984cd3714556a1baf9ac4773104f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4590d95177e4db78cd604baf121befd"}},"metadata":{}}]},{"cell_type":"markdown","source":"### Define Preprocess Function","metadata":{}},{"cell_type":"code","source":"prefix = \"summarize: \"\n\n\ndef preprocess_function(examples):\n    inputs = [prefix + doc for doc in examples[\"dialogue\"]]\n    model_inputs = tokenizer(inputs, max_length=1024, truncation=True)\n\n    labels = tokenizer(text_target=examples[\"summary\"], max_length=128, truncation=True)\n\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2024-02-18T16:21:14.592121Z","iopub.execute_input":"2024-02-18T16:21:14.592626Z","iopub.status.idle":"2024-02-18T16:21:14.599799Z","shell.execute_reply.started":"2024-02-18T16:21:14.592599Z","shell.execute_reply":"2024-02-18T16:21:14.598835Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### Preprocess Data","metadata":{}},{"cell_type":"code","source":"tokenized_data = modified_data.map(preprocess_function,batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T16:21:14.601009Z","iopub.execute_input":"2024-02-18T16:21:14.601326Z","iopub.status.idle":"2024-02-18T16:21:15.508757Z","shell.execute_reply.started":"2024-02-18T16:21:14.601303Z","shell.execute_reply":"2024-02-18T16:21:15.507814Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53e16aaca9d844cdad57c4451b6b6d49"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"682a43192f5f441aa1236c852ca4151a"}},"metadata":{}}]},{"cell_type":"markdown","source":"### Define Data Collator","metadata":{}},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T16:21:29.476918Z","iopub.execute_input":"2024-02-18T16:21:29.477755Z","iopub.status.idle":"2024-02-18T16:21:40.164172Z","shell.execute_reply.started":"2024-02-18T16:21:29.477726Z","shell.execute_reply":"2024-02-18T16:21:40.163160Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"2024-02-18 16:21:31.834412: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-18 16:21:31.834517: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-18 16:21:31.956925: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nException ignored in: <function _xla_gc_callback at 0x7fbbf72fdea0>\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/jax/_src/lib/__init__.py\", line 97, in _xla_gc_callback\n    def _xla_gc_callback(*args):\nKeyboardInterrupt: \n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Load Rouge Metrics","metadata":{}},{"cell_type":"code","source":"import evaluate\n\nrouge = evaluate.load(\"rouge\")","metadata":{"execution":{"iopub.status.busy":"2024-02-18T16:21:40.166340Z","iopub.execute_input":"2024-02-18T16:21:40.167466Z","iopub.status.idle":"2024-02-18T16:21:44.127454Z","shell.execute_reply.started":"2024-02-18T16:21:40.167429Z","shell.execute_reply":"2024-02-18T16:21:44.126410Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c6d8c56d2cd4d33a2a9860230e87bfc"}},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\n\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n\n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n    result[\"gen_len\"] = np.mean(prediction_lens)\n\n    return {k: round(v, 4) for k, v in result.items()}","metadata":{"execution":{"iopub.status.busy":"2024-02-18T16:21:44.128995Z","iopub.execute_input":"2024-02-18T16:21:44.129367Z","iopub.status.idle":"2024-02-18T16:21:44.137299Z","shell.execute_reply.started":"2024-02-18T16:21:44.129334Z","shell.execute_reply":"2024-02-18T16:21:44.136134Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### Initialize model","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T16:21:44.140165Z","iopub.execute_input":"2024-02-18T16:21:44.140544Z","iopub.status.idle":"2024-02-18T16:21:46.913297Z","shell.execute_reply.started":"2024-02-18T16:21:44.140512Z","shell.execute_reply":"2024-02-18T16:21:46.912239Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d6b8f602dea402f951f51455d445ad7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4eb64e93f734634b5e6aa4aab2e95fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72384f5ba4f04b23ba7ca6cd6fda5b20"}},"metadata":{}}]},{"cell_type":"markdown","source":"### Define Training Arguments and start Finetuning","metadata":{}},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir=\"T5-small-summarization\",\n    evaluation_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    weight_decay=0.01,\n    save_total_limit=3,\n    num_train_epochs=10,\n    predict_with_generate=True,\n    fp16=True,\n    push_to_hub=True,\n)\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_data[\"train\"],\n    eval_dataset=tokenized_data[\"test\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-02-18T16:21:46.914692Z","iopub.execute_input":"2024-02-18T16:21:46.915062Z","iopub.status.idle":"2024-02-18T16:32:40.983747Z","shell.execute_reply.started":"2024-02-18T16:21:46.915026Z","shell.execute_reply":"2024-02-18T16:32:40.982743Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.3 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.2"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240218_162206-1nnjcdoq</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/likhith25/huggingface/runs/1nnjcdoq' target=\"_blank\">red-monkey-10</a></strong> to <a href='https://wandb.ai/likhith25/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/likhith25/huggingface' target=\"_blank\">https://wandb.ai/likhith25/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/likhith25/huggingface/runs/1nnjcdoq' target=\"_blank\">https://wandb.ai/likhith25/huggingface/runs/1nnjcdoq</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='630' max='630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [630/630 09:59, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge1</th>\n      <th>Rouge2</th>\n      <th>Rougel</th>\n      <th>Rougelsum</th>\n      <th>Gen Len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>2.116498</td>\n      <td>0.338000</td>\n      <td>0.118600</td>\n      <td>0.281100</td>\n      <td>0.281300</td>\n      <td>16.759500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>2.021013</td>\n      <td>0.361200</td>\n      <td>0.133800</td>\n      <td>0.298200</td>\n      <td>0.298500</td>\n      <td>16.559200</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>1.983838</td>\n      <td>0.365200</td>\n      <td>0.138400</td>\n      <td>0.303400</td>\n      <td>0.304000</td>\n      <td>16.119700</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>1.962277</td>\n      <td>0.371500</td>\n      <td>0.142000</td>\n      <td>0.307700</td>\n      <td>0.307900</td>\n      <td>16.230800</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>No log</td>\n      <td>1.951277</td>\n      <td>0.372700</td>\n      <td>0.144100</td>\n      <td>0.308000</td>\n      <td>0.308400</td>\n      <td>16.145300</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>No log</td>\n      <td>1.941851</td>\n      <td>0.375000</td>\n      <td>0.143800</td>\n      <td>0.309000</td>\n      <td>0.309300</td>\n      <td>16.223400</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>No log</td>\n      <td>1.937559</td>\n      <td>0.374800</td>\n      <td>0.144000</td>\n      <td>0.310200</td>\n      <td>0.310400</td>\n      <td>16.146500</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>2.245200</td>\n      <td>1.932376</td>\n      <td>0.375400</td>\n      <td>0.145100</td>\n      <td>0.309800</td>\n      <td>0.309900</td>\n      <td>16.189300</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>2.245200</td>\n      <td>1.930173</td>\n      <td>0.376900</td>\n      <td>0.145900</td>\n      <td>0.311200</td>\n      <td>0.311300</td>\n      <td>16.196600</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>2.245200</td>\n      <td>1.929430</td>\n      <td>0.377200</td>\n      <td>0.145300</td>\n      <td>0.310500</td>\n      <td>0.310600</td>\n      <td>16.183200</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1128: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1128: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=630, training_loss=2.2192771790519594, metrics={'train_runtime': 652.2761, 'train_samples_per_second': 30.662, 'train_steps_per_second': 0.966, 'total_flos': 2419847968849920.0, 'train_loss': 2.2192771790519594, 'epoch': 10.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"### Push To huggingface Hub","metadata":{}},{"cell_type":"code","source":"trainer.push_to_hub()","metadata":{"execution":{"iopub.status.busy":"2024-02-18T16:32:40.985607Z","iopub.execute_input":"2024-02-18T16:32:40.986409Z","iopub.status.idle":"2024-02-18T16:32:48.679464Z","shell.execute_reply.started":"2024-02-18T16:32:40.986368Z","shell.execute_reply":"2024-02-18T16:32:48.678415Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e72665811db047f493dac905851ecfe8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1708273308.6a6946c5f35f.109.0:   0%|          | 0.00/11.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dcbf235dad3a47479252af4cded21b7e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ed919db997349459e48346c3dbcf778"}},"metadata":{}},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/likhith231/T5-small-summarization/commit/7481be01bf76991cf17bcf1e91caa65e2988dced', commit_message='End of training', commit_description='', oid='7481be01bf76991cf17bcf1e91caa65e2988dced', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"markdown","source":"### Inference","metadata":{}},{"cell_type":"code","source":"text = \"summarize: The Inflation Reduction Act lowers prescription drug costs, health care costs, and energy costs. It's the most aggressive action on tackling the climate crisis in American history, which will lift up American workers and create good-paying, union jobs across the country. It'll lower the deficit and ask the ultra-wealthy and corporations to pay their fair share. And no one making under $400,000 per year will pay a penny more in taxes.\"\n","metadata":{"execution":{"iopub.status.busy":"2024-02-18T16:32:48.680894Z","iopub.execute_input":"2024-02-18T16:32:48.681258Z","iopub.status.idle":"2024-02-18T16:32:48.688123Z","shell.execute_reply.started":"2024-02-18T16:32:48.681221Z","shell.execute_reply":"2024-02-18T16:32:48.687178Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from transformers import pipeline\n\nsummarizer = pipeline(\"summarization\", model=\"likhith231/T5-small-summarization\")\nsummarizer(text)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T16:33:09.561767Z","iopub.execute_input":"2024-02-18T16:33:09.562640Z","iopub.status.idle":"2024-02-18T16:33:14.647881Z","shell.execute_reply.started":"2024-02-18T16:33:09.562607Z","shell.execute_reply":"2024-02-18T16:33:14.646990Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.50k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33cc31495e854c88bd2e20b3f7b9a74b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"069e8298fd0f438c90d9528e95bdf404"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1986db5c8bd84a328621585ba88cea05"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/20.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ade2ea15c584af3af5081cecdacd5ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"199153ce7b834b728ce31eea04d956f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd2ff66951de4af2b12bf5d7efd14ca3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6072baefe5fe4b8e94125896e2f8a1d4"}},"metadata":{}},{"name":"stderr","text":"Your max_length is set to 200, but your input_length is only 103. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=51)\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"[{'summary_text': \"the Inflation Reduction Act lowers prescription drug costs, health care costs, and energy costs. It's the most aggressive action on tackling the climate crisis in American history.\"}]"},"metadata":{}}]},{"cell_type":"code","source":"text1= \"The history of India is a tapestry woven with the threads of ancient civilizations, remarkable empires, and diverse cultures. From the sophisticated urban planning of the Indus Valley Civilization to the grandeur of the Maurya Empire under Ashoka's rule, India's past is a saga of innovation, conquest, and enlightenment. The Gupta Dynasty ushered in a golden age of art, science, and literature, while the Mughal Empire left an indelible mark with its architectural marvels like the Taj Mahal. The struggle for independence led by Mahatma Gandhi against British colonial rule culminated in 1947, marking the birth of modern India as a sovereign nation. Today, India stands as a vibrant mosaic of tradition and modernity, shaped by the rich tapestry of its historical legacy.\"\nsummarizer(text1)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T16:33:18.801406Z","iopub.execute_input":"2024-02-18T16:33:18.802404Z","iopub.status.idle":"2024-02-18T16:33:21.387249Z","shell.execute_reply.started":"2024-02-18T16:33:18.802361Z","shell.execute_reply":"2024-02-18T16:33:21.386183Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"Your max_length is set to 200, but your input_length is only 195. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=97)\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"[{'summary_text': \"India's history is a tapestry woven with the threads of ancient civilizations, remarkable empires, and diverse cultures. The Gupta Dynasty ushered in a golden age of art, science, and literature, while the Mughal Empire left an indelible mark with its architectural marvels like Taj Mahal.\"}]"},"metadata":{}}]},{"cell_type":"code","source":"text2= \"The history of Germany is a riveting tale of triumphs, setbacks, and resilience that has shaped the course of Europe and the world. From the legendary battles of the Germanic tribes against the Roman Empire to the formation of the Holy Roman Empire under Charlemagne's reign, Germany's early history is marked by a complex tapestry of kingdoms and principalities. The Renaissance and Reformation periods brought profound cultural and religious transformations, with figures like Martin Luther sparking movements that reverberated across Europe.The rise of Prussia in the 18th century laid the groundwork for German unification, culminating in the formation of the German Empire under Otto von Bismarck's leadership in 1871. However, the empire's ambitions would contribute to the outbreak of two devastating world wars in the 20th century, with Germany emerging as a central player in both conflicts.\"\nsummarizer(text2)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T16:33:24.054538Z","iopub.execute_input":"2024-02-18T16:33:24.055292Z","iopub.status.idle":"2024-02-18T16:33:26.130345Z","shell.execute_reply.started":"2024-02-18T16:33:24.055260Z","shell.execute_reply":"2024-02-18T16:33:26.129225Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"Your max_length is set to 200, but your input_length is only 198. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=99)\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"[{'summary_text': \"Germany's early history is marked by a complex tapestry of kingdoms and principalities. The rise of Prussia in the 18th century laid the groundwork for German unification, culminating in the formation of the German Empire under Otto von Bismarck's leadership in 1871.\"}]"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}